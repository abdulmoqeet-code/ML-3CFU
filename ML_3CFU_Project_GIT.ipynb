{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsaEj1ZjZrDv"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.transforms import ToTensor, Resize, Normalize, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision.models import vgg19, VGG19_Weights\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting data\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Wider-Face/train/sharp/CelebA.zip'\n",
        "extracted_path = '/content/data/CelebA'\n",
        "os.makedirs(extracted_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "print(f\"Extracted files to: {extracted_path}\")\n"
      ],
      "metadata": {
        "id": "xAL3pNNJZ0cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "OaX2JyGDZ3lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Data class\n",
        "class PairedSRDataset(Dataset):\n",
        "    def __init__(self, root_dir, lr_folder='blur', hr_folder='sharp', lr_size=32):\n",
        "        self.lr_size = lr_size\n",
        "        self.hr_size = lr_size * 4  # 4Ã— upscale\n",
        "\n",
        "        lr_files = sorted(glob(os.path.join(root_dir, lr_folder, '*')))\n",
        "        hr_files = sorted(glob(os.path.join(root_dir, hr_folder, '*')))\n",
        "\n",
        "        # Create a dictionary of HR files for quick lookup by base name\n",
        "        hr_dict = {os.path.splitext(os.path.basename(f))[0]: f for f in hr_files}\n",
        "\n",
        "        self.lr_paths = []\n",
        "        self.hr_paths = []\n",
        "\n",
        "        # Find matching LR and HR files based on base name\n",
        "        for lr_path in lr_files:\n",
        "            lr_base_name = os.path.splitext(os.path.basename(lr_path))[0]\n",
        "            if lr_base_name in hr_dict:\n",
        "                self.lr_paths.append(lr_path)\n",
        "                self.hr_paths.append(hr_dict[lr_base_name])\n",
        "\n",
        "        print(f\"Found {len(self.lr_paths)} paired images.\")\n",
        "\n",
        "\n",
        "        self.transform_lr = Compose([Resize((self.lr_size, self.lr_size)), ToTensor(), Normalize((0.5,)*3, (0.5,)*3)])\n",
        "        self.transform_hr = Compose([Resize((self.hr_size, self.hr_size)), ToTensor(), Normalize((0.5,)*3, (0.5,)*3)])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lr = Image.open(self.lr_paths[idx]).convert('RGB')\n",
        "        hr = Image.open(self.hr_paths[idx]).convert('RGB')\n",
        "\n",
        "        return self.transform_lr(lr), self.transform_hr(hr)\n",
        "\n",
        "\n",
        "\n",
        "# Example: load training set\n",
        "train_ds = PairedSRDataset('/content/data/CelebA/CelebA/train')\n",
        "\n",
        "# Create subset of first 5k images\n",
        "subset_size = min(5000, len(train_ds))\n",
        "train_subset = Subset(train_ds, indices=range(subset_size))\n",
        "\n",
        "#Data loader\n",
        "train_loader = DataLoader(\n",
        "    train_subset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "5Y7K8saVZ6yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing image\n",
        "print(len(train_subset))\n",
        "#show image\n",
        "\n",
        "lr, hr = train_subset[0]  # Low-res and high-res tensors\n",
        "\n",
        "# Convert tensors back to images\n",
        "lr_img = TF.to_pil_image((lr * 0.5 + 0.5))  # De-normalize\n",
        "hr_img = TF.to_pil_image((hr * 0.5 + 0.5))  # De-normalize\n",
        "\n",
        "# Plot the images\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.title(\"Low Resolution\")\n",
        "plt.imshow(lr_img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"High Resolution\")\n",
        "plt.imshow(hr_img)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SWw2f5ZTZ78e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "class ResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
        "        super().__init__()\n",
        "        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.rdb1(x)\n",
        "        out = self.rdb2(out)\n",
        "        out = self.rdb3(out)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "class RRDBNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=3, num_feat=64, num_block=23, num_grow_ch=32):\n",
        "        super().__init__()\n",
        "        self.conv_first = nn.Conv2d(in_ch, num_feat, 3, 1, 1)\n",
        "        self.body = nn.Sequential(*[RRDB(num_feat, num_grow_ch) for _ in range(num_block)])\n",
        "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_last = nn.Conv2d(num_feat, out_ch, 3, 1, 1)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.conv_first(x)\n",
        "        body_feat = self.conv_body(self.body(feat))\n",
        "        feat = feat + body_feat\n",
        "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        feat = self.conv_hr(feat)\n",
        "        out = self.conv_last(feat)\n",
        "        return out\n",
        "\n",
        "#Discriminator\n",
        "class VGGStyleDiscriminator(nn.Module):\n",
        "    def __init__(self, in_ch=3, num_feat=64):\n",
        "        super().__init__()\n",
        "        self.conv0_0 = nn.Conv2d(in_ch, num_feat, 3, 1, 1)\n",
        "        self.conv0_1 = nn.Conv2d(num_feat, num_feat, 4, 2, 1, bias=False)\n",
        "        self.lrelu = nn.LeakyReLU(0.2, True)\n",
        "\n",
        "        # Downsampling blocks\n",
        "        self.conv1_0 = nn.Conv2d(num_feat, num_feat * 2, 3, 1, 1, bias=False)\n",
        "        self.conv1_1 = nn.Conv2d(num_feat * 2, num_feat * 2, 4, 2, 1, bias=False)\n",
        "\n",
        "        self.conv2_0 = nn.Conv2d(num_feat * 2, num_feat * 4, 3, 1, 1, bias=False)\n",
        "        self.conv2_1 = nn.Conv2d(num_feat * 4, num_feat * 4, 4, 2, 1, bias=False)\n",
        "\n",
        "        self.conv3_0 = nn.Conv2d(num_feat * 4, num_feat * 8, 3, 1, 1, bias=False)\n",
        "        self.conv3_1 = nn.Conv2d(num_feat * 8, num_feat * 8, 4, 2, 1, bias=False)\n",
        "\n",
        "        # Final layers\n",
        "        self.conv4 = nn.Conv2d(num_feat * 8, 1, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lrelu(self.conv0_0(x))\n",
        "        x = self.lrelu(self.conv0_1(x))\n",
        "        x = self.lrelu(self.conv1_0(x))\n",
        "        x = self.lrelu(self.conv1_1(x))\n",
        "        x = self.lrelu(self.conv2_0(x))\n",
        "        x = self.lrelu(self.conv2_1(x))\n",
        "        x = self.lrelu(self.conv3_0(x))\n",
        "        x = self.lrelu(self.conv3_1(x))\n",
        "        x = self.conv4(x)\n",
        "        return x\n",
        "\n",
        "# Loss Functions, perceptual loss\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Using pretrained-vgg to extract the feature\n",
        "        vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features[:35].eval()\n",
        "        for param in vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.vgg = vgg\n",
        "        self.criterion = nn.L1Loss()\n",
        "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
        "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
        "\n",
        "    def forward(self, fake, real):\n",
        "        fake = (fake - self.mean.to(fake.device)) / self.std.to(fake.device)\n",
        "        real = (real - self.mean.to(real.device)) / self.std.to(real.device)\n",
        "        features_fake = self.vgg(fake)\n",
        "        features_real = self.vgg(real) # No need to detach here, as VGG has no grads\n",
        "        return self.criterion(features_fake, features_real)\n",
        "\n",
        "# Relativistic average Discriminator Loss\n",
        "class RelativisticDiscriminatorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, pred_real, pred_fake):\n",
        "        real_logit = pred_real - torch.mean(pred_fake)\n",
        "        fake_logit = pred_fake - torch.mean(pred_real)\n",
        "        return self.bce(real_logit, torch.ones_like(real_logit)) + \\\n",
        "               self.bce(fake_logit, torch.zeros_like(fake_logit))\n",
        "\n",
        "# Relativistic average Generator Loss\n",
        "class RelativisticGeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, pred_real, pred_fake):\n",
        "\n",
        "        real_logit = pred_real - torch.mean(pred_fake)\n",
        "        fake_logit = pred_fake - torch.mean(pred_real)\n",
        "        return self.bce(real_logit, torch.zeros_like(real_logit)) + \\\n",
        "               self.bce(fake_logit, torch.ones_like(fake_logit))\n",
        "\n",
        "class CombinedGeneratorLoss(nn.Module):\n",
        "    def __init__(self, w_adv=0.005, w_perceptual=1.0, w_l1=0.01):\n",
        "        super().__init__()\n",
        "        self.w_adv = w_adv\n",
        "        self.w_perceptual = w_perceptual\n",
        "        self.w_l1 = w_l1\n",
        "        self.perceptual = PerceptualLoss()\n",
        "        self.adversarial = RelativisticGeneratorLoss()\n",
        "        self.l1 = nn.L1Loss()\n",
        "\n",
        "    def forward(self, fake_hr, real_hr, pred_fake, pred_real):\n",
        "        adv_loss = self.adversarial(pred_real, pred_fake)\n",
        "        perceptual_loss = self.perceptual(fake_hr, real_hr)\n",
        "        l1_loss = self.l1(fake_hr, real_hr)\n",
        "\n",
        "        return (self.w_adv * adv_loss +\n",
        "                self.w_perceptual * perceptual_loss +\n",
        "                self.w_l1 * l1_loss)\n"
      ],
      "metadata": {
        "id": "Yb4afIs8Z-EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training part\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize models\n",
        "generator = RRDBNet(in_ch=3, out_ch=3, num_feat=64, num_block=23, num_grow_ch=32).to(device)\n",
        "discriminator = VGGStyleDiscriminator(in_ch=3, num_feat=64).to(device)\n",
        "\n",
        "# Load pretrained generator weights\n",
        "weights_path = \"/content/drive/MyDrive/RealESRGAN_x4.pth\"\n",
        "state_dict = torch.load(weights_path)\n",
        "\n",
        "# pretrained weight of esrgan\n",
        "if 'params_ema' in state_dict:\n",
        "    clean_state_dict = state_dict['params_ema']\n",
        "elif 'params' in state_dict:\n",
        "    clean_state_dict = state_dict['params']\n",
        "else:\n",
        "    clean_state_dict = state_dict\n",
        "\n",
        "generator.load_state_dict(clean_state_dict, strict=True)\n",
        "print(\"Loaded\")\n",
        "\n",
        "\n",
        "# Freeze all parameters in the generator\n",
        "for param in generator.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#  Unfreeze only the desired layers for fine-tuning\n",
        "for name, param in generator.named_parameters():\n",
        "    if 'conv_last' in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"Unfrozen for training: {name}\")\n",
        "\n",
        "# optimizer\n",
        "opt_g = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, generator.parameters()),\n",
        "    lr=1e-5,  # Use a smaller learning rate for fine-tuning\n",
        "    betas=(0.9, 0.999)\n",
        ")\n",
        "# The discriminator will be trained from scratch\n",
        "opt_d = optim.Adam(discriminator.parameters(), lr=2e-5, betas=(0.9, 0.999))\n",
        "\n",
        "# 4. Initialize Loss Functions\n",
        "g_loss_fn = CombinedGeneratorLoss().to(device)\n",
        "d_loss_fn = RelativisticDiscriminatorLoss().to(device)\n",
        "\n",
        "# 5. Initialize AMP GradScalers for performance\n",
        "g_scaler = GradScaler()\n",
        "d_scaler = GradScaler()\n",
        "\n"
      ],
      "metadata": {
        "id": "DBnY98FvaBZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training LOop\n",
        "NUM_EPOCHS = 25\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    for batch_idx, (lr_imgs, hr_imgs) in progress_bar:\n",
        "        lr_imgs = lr_imgs.to(device)\n",
        "        hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "\n",
        "        # Train Discriminator\n",
        "\n",
        "        opt_d.zero_grad()\n",
        "\n",
        "        with autocast(str(device)):\n",
        "            with torch.no_grad():\n",
        "                fake_hr = generator(lr_imgs)\n",
        "\n",
        "            pred_real = discriminator(hr_imgs)\n",
        "            pred_fake = discriminator(fake_hr.detach())\n",
        "            d_loss = d_loss_fn(pred_real, pred_fake)\n",
        "\n",
        "        d_scaler.scale(d_loss).backward()\n",
        "        d_scaler.step(opt_d)\n",
        "        d_scaler.update()\n",
        "\n",
        "\n",
        "        #  Train Generator\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "\n",
        "        with autocast(str(device)):\n",
        "            # Re-generate fake images to build computation graph for generator\n",
        "            fake_hr = generator(lr_imgs)\n",
        "            pred_fake = discriminator(fake_hr)\n",
        "            pred_real = discriminator(hr_imgs).detach()\n",
        "\n",
        "            g_loss = g_loss_fn(fake_hr, hr_imgs, pred_fake, pred_real)\n",
        "\n",
        "        g_scaler.scale(g_loss).backward()\n",
        "        g_scaler.step(opt_g)\n",
        "        g_scaler.update()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix(G_Loss=f'{g_loss.item():.4f}', D_Loss=f'{d_loss.item():.4f}')\n",
        "\n",
        "    print(f\"\\n End of Epoch {epoch+1}\")\n",
        "\n",
        "    # Optional: clean GPU cache\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Save checkpoint\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save({\n",
        "            'generator': generator.state_dict(),\n",
        "            'discriminator': discriminator.state_dict(),\n",
        "            'opt_g': opt_g.state_dict(),\n",
        "            'opt_d': opt_d.state_dict(),\n",
        "            'epoch': epoch,\n",
        "        }, f\"finetuned_realesrgan_epoch_{epoch+1}.pth\")\n",
        "        print(f\"Saved checkpoint for epoch {epoch+1}\")"
      ],
      "metadata": {
        "id": "mHa1MPqSaEEe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}